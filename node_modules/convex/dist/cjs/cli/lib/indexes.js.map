{
  "version": 3,
  "sources": ["../../../../src/cli/lib/indexes.ts"],
  "sourcesContent": ["import chalk from \"chalk\";\nimport path from \"path\";\nimport { bundleSchema } from \"../../bundler/index.js\";\nimport { Context } from \"../../bundler/context.js\";\nimport {\n  changeSpinner,\n  logFailure,\n  logFinishedStep,\n  logError,\n} from \"../../bundler/log.js\";\nimport {\n  poll,\n  logAndHandleFetchError,\n  deploymentFetch,\n  deprecationCheckWarning,\n} from \"./utils/utils.js\";\nimport { deploymentDashboardUrlPage } from \"./dashboard.js\";\n\ntype IndexMetadata = {\n  table: string;\n  name: string;\n  fields:\n    | string[]\n    | {\n        searchField: string;\n        filterFields: string[];\n      };\n  backfill: {\n    state: \"in_progress\" | \"done\";\n  };\n  staged: boolean;\n};\n\ntype SchemaState =\n  | { state: \"pending\" }\n  | { state: \"validated\" }\n  | { state: \"active\" }\n  | { state: \"overwritten\" }\n  | { state: \"failed\"; error: string; tableName?: string };\n\ntype SchemaStateResponse = {\n  indexes: IndexMetadata[];\n  schemaState: SchemaState;\n};\ntype PrepareSchemaResponse = {\n  added: IndexMetadata[];\n  dropped: IndexMetadata[];\n  enabled: IndexMetadata[];\n  disabled: IndexMetadata[];\n  schemaId: string;\n};\n\nexport async function pushSchema(\n  ctx: Context,\n  origin: string,\n  adminKey: string,\n  schemaDir: string,\n  dryRun: boolean,\n  deploymentName: string | null,\n): Promise<{ schemaId?: string; schemaState?: SchemaState }> {\n  if (\n    !ctx.fs.exists(path.resolve(schemaDir, \"schema.ts\")) &&\n    !ctx.fs.exists(path.resolve(schemaDir, \"schema.js\"))\n  ) {\n    // Don't do anything.\n    return {};\n  }\n  const bundles = await bundleSchema(ctx, schemaDir, []);\n\n  changeSpinner(\"Checking for index or schema changes...\");\n\n  let data: PrepareSchemaResponse;\n  const fetch = deploymentFetch(ctx, {\n    deploymentUrl: origin,\n    adminKey,\n  });\n  try {\n    const res = await fetch(\"/api/prepare_schema\", {\n      method: \"POST\",\n      body: JSON.stringify({\n        bundle: bundles[0],\n        adminKey,\n        dryRun,\n      }),\n    });\n    deprecationCheckWarning(ctx, res);\n    data = await res.json();\n  } catch (err: unknown) {\n    logFailure(`Error: Unable to run schema validation on ${origin}`);\n    return await logAndHandleFetchError(ctx, err);\n  }\n\n  logIndexChanges(data, dryRun, deploymentName);\n  const schemaId = data.schemaId;\n  const schemaState = await waitForReadySchema(\n    ctx,\n    origin,\n    adminKey,\n    schemaId,\n    deploymentName,\n  );\n  return { schemaId, schemaState };\n}\n\n/// Wait for indexes to build and schema to be validated.\nasync function waitForReadySchema(\n  ctx: Context,\n  origin: string,\n  adminKey: string,\n  schemaId: string,\n  deploymentName: string | null,\n): Promise<SchemaState> {\n  const path = `api/schema_state/${schemaId}`;\n  const depFetch = deploymentFetch(ctx, {\n    deploymentUrl: origin,\n    adminKey,\n  });\n  const fetch = async () => {\n    try {\n      const resp = await depFetch(path, { method: \"GET\" });\n      const data: SchemaStateResponse = await resp.json();\n      return data;\n    } catch (err: unknown) {\n      logFailure(\n        `Error: Unable to build indexes and run schema validation on ${origin}`,\n      );\n      return await logAndHandleFetchError(ctx, err);\n    }\n  };\n\n  // Set the spinner to the default progress message before the first `fetch` call returns.\n  const start = Date.now();\n\n  setSchemaProgressSpinner(null, start, deploymentName);\n\n  const data = await poll(fetch, (data: SchemaStateResponse) => {\n    setSchemaProgressSpinner(data, start, deploymentName);\n    return (\n      data.indexes.every(\n        (index) => index.backfill.state === \"done\" || index.staged,\n      ) && data.schemaState.state !== \"pending\"\n    );\n  });\n\n  switch (data.schemaState.state) {\n    case \"failed\":\n      // Schema validation failed. This could be either because the data\n      // is bad or the schema is wrong. Classify this as a filesystem error\n      // because adjusting `schema.ts` is the most normal next step.\n      logFailure(\"Schema validation failed\");\n      logError(chalk.red(`${data.schemaState.error}`));\n      return await ctx.crash({\n        exitCode: 1,\n        errorType: {\n          \"invalid filesystem or db data\": data.schemaState.tableName\n            ? {\n                tableName: data.schemaState.tableName,\n              }\n            : null,\n        },\n        printedMessage: null, // TODO - move logging into here\n      });\n\n    case \"overwritten\":\n      return await ctx.crash({\n        exitCode: 1,\n        errorType: \"fatal\",\n        printedMessage: `Schema was overwritten by another push.`,\n      });\n    case \"validated\":\n      logFinishedStep(\"Schema validation complete.\");\n      break;\n    case \"active\":\n      break;\n  }\n  return data.schemaState;\n}\n\nfunction setSchemaProgressSpinner(\n  data: SchemaStateResponse | null,\n  start: number,\n  deploymentName: string | null,\n) {\n  if (!data) {\n    changeSpinner(\"Pushing code to your deployment...\");\n    return;\n  }\n  const indexesCompleted = data.indexes.filter(\n    (index) => index.backfill.state === \"done\",\n  ).length;\n  const numIndexes = data.indexes.length;\n\n  const indexesDone = indexesCompleted === numIndexes;\n  const schemaDone = data.schemaState.state !== \"pending\";\n\n  if (indexesDone && schemaDone) {\n    return;\n  }\n\n  let msg = \"Pushing your code to your Convex deployment...\";\n  if (!indexesDone && !schemaDone) {\n    msg = `Backfilling indexes (${indexesCompleted}/${numIndexes} ready) and checking that documents match your schema...`;\n  } else if (!indexesDone) {\n    if (Date.now() - start > 10_000) {\n      for (const index of data.indexes) {\n        if (index.backfill.state === \"in_progress\") {\n          const dashboardUrl = deploymentDashboardUrlPage(\n            deploymentName,\n            `/data?table=${index.table}&showIndexes=true`,\n          );\n          msg = `Backfilling index ${index.name} (${indexesCompleted}/${numIndexes} ready), \\\nsee progress: ${dashboardUrl}`;\n          break;\n        }\n      }\n    } else {\n      msg = `Backfilling indexes (${indexesCompleted}/${numIndexes} ready)...`;\n    }\n  } else {\n    msg = \"Checking that documents match your schema...\";\n  }\n  changeSpinner(msg);\n}\n\nfunction logIndexChanges(\n  indexes: PrepareSchemaResponse,\n  dryRun: boolean,\n  deploymentName: string | null,\n) {\n  if (indexes.dropped.length > 0) {\n    let indexDiff = \"\";\n    for (const index of indexes.dropped) {\n      indexDiff += `  [-] ${stringifyIndex(index)}\\n`;\n    }\n    // strip last new line\n    indexDiff = indexDiff.slice(0, -1);\n    logFinishedStep(\n      `${dryRun ? \"Would delete\" : \"Deleted\"} table indexes:\\n${indexDiff}`,\n    );\n  }\n  const addedStaged = indexes.added.filter((index) => index.staged);\n  const addedEnabled = indexes.added.filter((index) => !index.staged);\n  if (addedEnabled.length > 0) {\n    let indexDiff = \"\";\n    for (const index of addedEnabled) {\n      indexDiff += `  [+] ${stringifyIndex(index)}\\n`;\n    }\n    // strip last new line\n    indexDiff = indexDiff.slice(0, -1);\n    logFinishedStep(\n      `${dryRun ? \"Would add\" : \"Added\"} table indexes:\\n${indexDiff}`,\n    );\n  }\n  if (addedStaged.length > 0) {\n    let indexDiff = \"\";\n    for (const index of addedStaged) {\n      const progressLink = deploymentDashboardUrlPage(\n        deploymentName,\n        `/data?table=${index.table}&showIndexes=true`,\n      );\n      indexDiff += `  [+] ${stringifyIndex(index)}, see progress: ${progressLink}\\n`;\n    }\n    // strip last new line\n    indexDiff = indexDiff.slice(0, -1);\n    logFinishedStep(\n      `${dryRun ? \"Would add\" : \"Added\"} staged table indexes:\\n${indexDiff}`,\n    );\n  }\n  if (indexes.enabled.length > 0) {\n    let indexDiff = \"\";\n    for (const index of indexes.enabled) {\n      indexDiff += `  [*] ${stringifyIndex(index)}\\n`;\n    }\n    // strip last new line\n    indexDiff = indexDiff.slice(0, -1);\n    const text = dryRun\n      ? `These indexes would be enabled`\n      : `These indexes are now enabled`;\n    logFinishedStep(`${text}:\\n${indexDiff}`);\n  }\n  if (indexes.disabled.length > 0) {\n    let indexDiff = \"\";\n    for (const index of indexes.disabled) {\n      indexDiff += `  [*] ${stringifyIndex(index)}\\n`;\n    }\n    // strip last new line\n    indexDiff = indexDiff.slice(0, -1);\n    const text = dryRun\n      ? `These indexes would be staged`\n      : `These indexes are now staged`;\n    logFinishedStep(`${text}:\\n${indexDiff}`);\n  }\n}\n\nfunction stringifyIndex(index: IndexMetadata) {\n  return `${index.table}.${index.name} ${JSON.stringify(index.fields)}`;\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAAkB;AAClB,kBAAiB;AACjB,qBAA6B;AAE7B,iBAKO;AACP,mBAKO;AACP,uBAA2C;AAoC3C,eAAsB,WACpB,KACA,QACA,UACA,WACA,QACA,gBAC2D;AAC3D,MACE,CAAC,IAAI,GAAG,OAAO,YAAAA,QAAK,QAAQ,WAAW,WAAW,CAAC,KACnD,CAAC,IAAI,GAAG,OAAO,YAAAA,QAAK,QAAQ,WAAW,WAAW,CAAC,GACnD;AAEA,WAAO,CAAC;AAAA,EACV;AACA,QAAM,UAAU,UAAM,6BAAa,KAAK,WAAW,CAAC,CAAC;AAErD,gCAAc,yCAAyC;AAEvD,MAAI;AACJ,QAAM,YAAQ,8BAAgB,KAAK;AAAA,IACjC,eAAe;AAAA,IACf;AAAA,EACF,CAAC;AACD,MAAI;AACF,UAAM,MAAM,MAAM,MAAM,uBAAuB;AAAA,MAC7C,QAAQ;AAAA,MACR,MAAM,KAAK,UAAU;AAAA,QACnB,QAAQ,QAAQ,CAAC;AAAA,QACjB;AAAA,QACA;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AACD,8CAAwB,KAAK,GAAG;AAChC,WAAO,MAAM,IAAI,KAAK;AAAA,EACxB,SAAS,KAAc;AACrB,+BAAW,6CAA6C,MAAM,EAAE;AAChE,WAAO,UAAM,qCAAuB,KAAK,GAAG;AAAA,EAC9C;AAEA,kBAAgB,MAAM,QAAQ,cAAc;AAC5C,QAAM,WAAW,KAAK;AACtB,QAAM,cAAc,MAAM;AAAA,IACxB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACA,SAAO,EAAE,UAAU,YAAY;AACjC;AAGA,eAAe,mBACb,KACA,QACA,UACA,UACA,gBACsB;AACtB,QAAMA,QAAO,oBAAoB,QAAQ;AACzC,QAAM,eAAW,8BAAgB,KAAK;AAAA,IACpC,eAAe;AAAA,IACf;AAAA,EACF,CAAC;AACD,QAAM,QAAQ,YAAY;AACxB,QAAI;AACF,YAAM,OAAO,MAAM,SAASA,OAAM,EAAE,QAAQ,MAAM,CAAC;AACnD,YAAMC,QAA4B,MAAM,KAAK,KAAK;AAClD,aAAOA;AAAA,IACT,SAAS,KAAc;AACrB;AAAA,QACE,+DAA+D,MAAM;AAAA,MACvE;AACA,aAAO,UAAM,qCAAuB,KAAK,GAAG;AAAA,IAC9C;AAAA,EACF;AAGA,QAAM,QAAQ,KAAK,IAAI;AAEvB,2BAAyB,MAAM,OAAO,cAAc;AAEpD,QAAM,OAAO,UAAM,mBAAK,OAAO,CAACA,UAA8B;AAC5D,6BAAyBA,OAAM,OAAO,cAAc;AACpD,WACEA,MAAK,QAAQ;AAAA,MACX,CAAC,UAAU,MAAM,SAAS,UAAU,UAAU,MAAM;AAAA,IACtD,KAAKA,MAAK,YAAY,UAAU;AAAA,EAEpC,CAAC;AAED,UAAQ,KAAK,YAAY,OAAO;AAAA,IAC9B,KAAK;AAIH,iCAAW,0BAA0B;AACrC,+BAAS,aAAAC,QAAM,IAAI,GAAG,KAAK,YAAY,KAAK,EAAE,CAAC;AAC/C,aAAO,MAAM,IAAI,MAAM;AAAA,QACrB,UAAU;AAAA,QACV,WAAW;AAAA,UACT,iCAAiC,KAAK,YAAY,YAC9C;AAAA,YACE,WAAW,KAAK,YAAY;AAAA,UAC9B,IACA;AAAA,QACN;AAAA,QACA,gBAAgB;AAAA;AAAA,MAClB,CAAC;AAAA,IAEH,KAAK;AACH,aAAO,MAAM,IAAI,MAAM;AAAA,QACrB,UAAU;AAAA,QACV,WAAW;AAAA,QACX,gBAAgB;AAAA,MAClB,CAAC;AAAA,IACH,KAAK;AACH,sCAAgB,6BAA6B;AAC7C;AAAA,IACF,KAAK;AACH;AAAA,EACJ;AACA,SAAO,KAAK;AACd;AAEA,SAAS,yBACP,MACA,OACA,gBACA;AACA,MAAI,CAAC,MAAM;AACT,kCAAc,oCAAoC;AAClD;AAAA,EACF;AACA,QAAM,mBAAmB,KAAK,QAAQ;AAAA,IACpC,CAAC,UAAU,MAAM,SAAS,UAAU;AAAA,EACtC,EAAE;AACF,QAAM,aAAa,KAAK,QAAQ;AAEhC,QAAM,cAAc,qBAAqB;AACzC,QAAM,aAAa,KAAK,YAAY,UAAU;AAE9C,MAAI,eAAe,YAAY;AAC7B;AAAA,EACF;AAEA,MAAI,MAAM;AACV,MAAI,CAAC,eAAe,CAAC,YAAY;AAC/B,UAAM,wBAAwB,gBAAgB,IAAI,UAAU;AAAA,EAC9D,WAAW,CAAC,aAAa;AACvB,QAAI,KAAK,IAAI,IAAI,QAAQ,KAAQ;AAC/B,iBAAW,SAAS,KAAK,SAAS;AAChC,YAAI,MAAM,SAAS,UAAU,eAAe;AAC1C,gBAAM,mBAAe;AAAA,YACnB;AAAA,YACA,eAAe,MAAM,KAAK;AAAA,UAC5B;AACA,gBAAM,qBAAqB,MAAM,IAAI,KAAK,gBAAgB,IAAI,UAAU,0BAClE,YAAY;AAClB;AAAA,QACF;AAAA,MACF;AAAA,IACF,OAAO;AACL,YAAM,wBAAwB,gBAAgB,IAAI,UAAU;AAAA,IAC9D;AAAA,EACF,OAAO;AACL,UAAM;AAAA,EACR;AACA,gCAAc,GAAG;AACnB;AAEA,SAAS,gBACP,SACA,QACA,gBACA;AACA,MAAI,QAAQ,QAAQ,SAAS,GAAG;AAC9B,QAAI,YAAY;AAChB,eAAW,SAAS,QAAQ,SAAS;AACnC,mBAAa,SAAS,eAAe,KAAK,CAAC;AAAA;AAAA,IAC7C;AAEA,gBAAY,UAAU,MAAM,GAAG,EAAE;AACjC;AAAA,MACE,GAAG,SAAS,iBAAiB,SAAS;AAAA,EAAoB,SAAS;AAAA,IACrE;AAAA,EACF;AACA,QAAM,cAAc,QAAQ,MAAM,OAAO,CAAC,UAAU,MAAM,MAAM;AAChE,QAAM,eAAe,QAAQ,MAAM,OAAO,CAAC,UAAU,CAAC,MAAM,MAAM;AAClE,MAAI,aAAa,SAAS,GAAG;AAC3B,QAAI,YAAY;AAChB,eAAW,SAAS,cAAc;AAChC,mBAAa,SAAS,eAAe,KAAK,CAAC;AAAA;AAAA,IAC7C;AAEA,gBAAY,UAAU,MAAM,GAAG,EAAE;AACjC;AAAA,MACE,GAAG,SAAS,cAAc,OAAO;AAAA,EAAoB,SAAS;AAAA,IAChE;AAAA,EACF;AACA,MAAI,YAAY,SAAS,GAAG;AAC1B,QAAI,YAAY;AAChB,eAAW,SAAS,aAAa;AAC/B,YAAM,mBAAe;AAAA,QACnB;AAAA,QACA,eAAe,MAAM,KAAK;AAAA,MAC5B;AACA,mBAAa,SAAS,eAAe,KAAK,CAAC,mBAAmB,YAAY;AAAA;AAAA,IAC5E;AAEA,gBAAY,UAAU,MAAM,GAAG,EAAE;AACjC;AAAA,MACE,GAAG,SAAS,cAAc,OAAO;AAAA,EAA2B,SAAS;AAAA,IACvE;AAAA,EACF;AACA,MAAI,QAAQ,QAAQ,SAAS,GAAG;AAC9B,QAAI,YAAY;AAChB,eAAW,SAAS,QAAQ,SAAS;AACnC,mBAAa,SAAS,eAAe,KAAK,CAAC;AAAA;AAAA,IAC7C;AAEA,gBAAY,UAAU,MAAM,GAAG,EAAE;AACjC,UAAM,OAAO,SACT,mCACA;AACJ,oCAAgB,GAAG,IAAI;AAAA,EAAM,SAAS,EAAE;AAAA,EAC1C;AACA,MAAI,QAAQ,SAAS,SAAS,GAAG;AAC/B,QAAI,YAAY;AAChB,eAAW,SAAS,QAAQ,UAAU;AACpC,mBAAa,SAAS,eAAe,KAAK,CAAC;AAAA;AAAA,IAC7C;AAEA,gBAAY,UAAU,MAAM,GAAG,EAAE;AACjC,UAAM,OAAO,SACT,kCACA;AACJ,oCAAgB,GAAG,IAAI;AAAA,EAAM,SAAS,EAAE;AAAA,EAC1C;AACF;AAEA,SAAS,eAAe,OAAsB;AAC5C,SAAO,GAAG,MAAM,KAAK,IAAI,MAAM,IAAI,IAAI,KAAK,UAAU,MAAM,MAAM,CAAC;AACrE;",
  "names": ["path", "data", "chalk"]
}
